{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_2_TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcFYRU9ucauJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4031b6ac-9ef8-4c69-d2fd-5629f5a50e6c"
      },
      "source": [
        "!wget https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\n",
        "!wget https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-12 07:46:42--  https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 64.233.189.128, 108.177.97.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘horse-or-human.zip.6’\n",
            "\n",
            "horse-or-human.zip. 100%[===================>] 142.65M   163MB/s    in 0.9s    \n",
            "\n",
            "2021-03-12 07:46:43 (163 MB/s) - ‘horse-or-human.zip.6’ saved [149574867/149574867]\n",
            "\n",
            "--2021-03-12 07:46:43--  https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.97.128, 108.177.125.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘validation-horse-or-human.zip.6’\n",
            "\n",
            "validation-horse-or 100%[===================>]  10.95M  25.1MB/s    in 0.4s    \n",
            "\n",
            "2021-03-12 07:46:44 (25.1 MB/s) - ‘validation-horse-or-human.zip.6’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QznhL656NNRZ"
      },
      "source": [
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten,  Dense, Flatten, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5HLAB_1KG6I"
      },
      "source": [
        "zip_validation_horse_or_human = zipfile.ZipFile('/content/validation-horse-or-human.zip', 'r')\n",
        "zip_validation_horse_or_human.extractall('validation-horse-or-human')\n",
        "zip_validation_horse_or_human.close()\n",
        "\n",
        "zip_horse_or_human = zipfile.ZipFile('/content/horse-or-human.zip', 'r')\n",
        "zip_horse_or_human.extractall('horse-or-human')\n",
        "zip_horse_or_human.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9h2qUzDXsnQ",
        "outputId": "1aabc7c4-bbd3-491a-c25c-bd9d6eee6474"
      },
      "source": [
        "batch_size=100\n",
        "image_size=(300, 300)\n",
        "train_dataset = image_dataset_from_directory('horse-or-human', label_mode='int', seed=42, \n",
        "                                       subset='training',\n",
        "                                       validation_split=0.2, \n",
        "                                       batch_size=batch_size, \n",
        "                                       image_size=image_size)\n",
        "\n",
        "validation_dataset = image_dataset_from_directory('validation-horse-or-human', label_mode='int', seed=42,\n",
        "                                             subset='validation',\n",
        "                                             validation_split=0.2,\n",
        "                                             batch_size=batch_size,\n",
        "                                             image_size=image_size)\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 files belonging to 2 classes.\n",
            "Using 822 files for training.\n",
            "Found 256 files belonging to 2 classes.\n",
            "Using 51 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xenEB8PCa1yb",
        "outputId": "aa525996-0c2e-4922-d9a3-c5295aa85f0e"
      },
      "source": [
        "input = Input(shape=(300, 300,3)) \n",
        "\n",
        "# Encoder\n",
        "conv1_1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input)\n",
        "pool1 = MaxPooling2D((2, 2), padding='same')(conv1_1)\n",
        "conv1_2 = Conv2D(16, (3, 3), activation='relu', padding='same')(pool1)\n",
        "pool2 = MaxPooling2D((2, 2), padding='same')(conv1_2)\n",
        "conv1_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool2)\n",
        "encoder = MaxPooling2D((2, 2), padding='same')(conv1_3)\n",
        "\n",
        "\n",
        "# Decoder\n",
        "conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(encoder)\n",
        "up1 = UpSampling2D((2, 2))(conv2_1)\n",
        "conv2_2 = Conv2D(16, (3, 3), activation='relu', padding='same')(up1)\n",
        "up2 = UpSampling2D((2, 2))(conv2_2)\n",
        "conv2_3 = Conv2D(32, (3, 3), activation='relu')(up2)\n",
        "up3 = UpSampling2D((2, 2))(conv2_3)\n",
        "decoder = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(up3)\n",
        "\n",
        "tmp = Flatten()(decoder)\n",
        "dence_1 = Dense(1024, activation='relu')(tmp)\n",
        "dropout_1 = Dropout(0.2)(dence_1)\n",
        "dence_2 = Dense(256, activation='relu')(dropout_1)\n",
        "dropout_2 = Dropout(0.2)(dence_2)\n",
        "output = Dense(2, activation='softmax')(dropout_2)\n",
        "\n",
        "autoencoder = Model(inputs=input, outputs=output)\n",
        "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "autoencoder.summary()\n",
        "\n",
        "# Обучаем модель\n",
        "history = autoencoder.fit(train_dataset,\n",
        "                    validation_data=validation_dataset,\n",
        "                    epochs=5,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 300, 300, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 300, 300, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 150, 150, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 150, 150, 16)      4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 75, 75, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 38, 38, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 38, 38, 8)         584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 76, 76, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 76, 76, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 152, 152, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 150, 150, 32)      4640      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 300, 300, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 300, 300, 3)       867       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 270000)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              276481024 \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 276,757,877\n",
            "Trainable params: 276,757,877\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "9/9 [==============================] - 240s 25s/step - loss: 0.3342 - accuracy: 0.5330 - val_loss: 0.2500 - val_accuracy: 0.5294\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 237s 25s/step - loss: 0.2500 - accuracy: 0.5061 - val_loss: 0.2500 - val_accuracy: 0.5294\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 247s 27s/step - loss: 0.2500 - accuracy: 0.5098 - val_loss: 0.2500 - val_accuracy: 0.5294\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 235s 25s/step - loss: 0.2500 - accuracy: 0.5159 - val_loss: 0.2500 - val_accuracy: 0.4706\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 234s 25s/step - loss: 0.2500 - accuracy: 0.5057 - val_loss: 0.2500 - val_accuracy: 0.4706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqZ-N6ukadN3"
      },
      "source": [
        "autoencoder.save(\"horse_or_human.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS40_FinagCk"
      },
      "source": [
        "files.download(\"horse_or_human.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}